{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoziTQ1d6NJLHZC4WaQRYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyrysake/My_Data_Science/blob/main/Hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpN7Rb_1FfCX",
        "outputId": "c2a58c06-d65a-44e8-92df-47742e164cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3162992 sha256=c7679be3865fe0277d18ed4eb9fe922ca506d54f082b07f95e8add83d98eb64b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import accuracy, Dataset, SVD, SVDpp, NMF\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "qlvNZtLUFon5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_movielens = Dataset.load_builtin(name = 'ml-100k' , prompt = True)\n",
        "\n",
        "algo_SVD = SVD()\n",
        "\n",
        "temp_SVD = cross_validate(algo_SVD, df_movielens, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "df_SVD = pd.DataFrame.from_dict(temp_SVD).mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7PcLQiWGES8",
        "outputId": "86e24b29-21c5-440b-9358-e4c5d326bbea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9354  0.9402  0.9359  0.9322  0.9374  0.9362  0.0026  \n",
            "MAE (testset)     0.7368  0.7419  0.7374  0.7348  0.7383  0.7378  0.0023  \n",
            "Fit time          1.30    1.35    1.32    1.56    1.62    1.43    0.13    \n",
            "Test time         0.12    0.20    0.14    0.32    0.12    0.18    0.08    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algo_SVDpp = SVDpp()\n",
        "\n",
        "temp_SVDpp = cross_validate(algo_SVDpp, df_movielens, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "df_SVDpp = pd.DataFrame.from_dict(temp_SVDpp).mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8o5bwI0TJ86",
        "outputId": "2232e36d-96f5-4357-ffdb-bf45ccb7ccbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9159  0.9169  0.9166  0.9222  0.9170  0.9177  0.0023  \n",
            "MAE (testset)     0.7177  0.7194  0.7197  0.7222  0.7210  0.7200  0.0015  \n",
            "Fit time          26.19   26.33   25.97   30.28   26.01   26.96   1.67    \n",
            "Test time         4.62    5.88    4.65    4.56    5.39    5.02    0.53    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algo_NMF = NMF()\n",
        "\n",
        "temp_NMF = cross_validate(algo_NMF, df_movielens, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "df_NMF = pd.DataFrame.from_dict(temp_NMF).mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIW0MaIsTMin",
        "outputId": "dc7a3c28-74c7-49a0-9cc8-f62818845369"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9651  0.9732  0.9518  0.9615  0.9630  0.9629  0.0069  \n",
            "MAE (testset)     0.7555  0.7665  0.7505  0.7566  0.7577  0.7574  0.0052  \n",
            "Fit time          2.09    2.10    2.12    2.12    2.73    2.23    0.25    \n",
            "Test time         0.11    0.22    0.10    0.17    0.22    0.16    0.05    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_comparison = pd.concat([df_SVD, df_SVDpp, df_NMF], axis=1)\n",
        "df_comparison.columns = ['SVD', 'SVDpp', 'NMF']\n",
        "\n",
        "print(df_comparison)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6ispw_vVRdq",
        "outputId": "c8f8a374-0945-4b3c-c808-3548a4930f3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                SVD      SVDpp       NMF\n",
            "test_rmse  0.936221   0.917717  0.962936\n",
            "test_mae   0.737832   0.720002  0.757362\n",
            "fit_time   1.430155  26.955281  2.230501\n",
            "test_time  0.183944   5.020117  0.163711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок\n",
        "1. test_rmse (RMSE): Чим нижче це значення, тим краще працює модель. За\n",
        "результатами тестування трьох алгоритмів найкраще впритул до ідеального RMSE у моделі SVD++ - 0.92.\n",
        "2. test_mae (MAE): Те ж саме стосується і цього показника - чим ближче до нуля, тим краще. Серед трьох алгоритмів кращий результат показала модель SVD++ з MAE = 0.72.\n",
        "3. fit_time: Це важливий параметр, що вказує на швидкість навчання моделі. Найбільш тривалий процес навчання виявився у моделі SVD++ з результатом 28.14 секунд, що означає, що ця модель навчається найдовше.\n",
        "4. test_time: Це також важливий показник, що вказує на швидкість роботи моделі з новими даними. У даному випадку, модель SVD++ вимагає більше часу на тестування (5.46 секунд), ніж інші моделі.\n"
      ],
      "metadata": {
        "id": "ganIzIdaVsKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Завдання з зірочкою"
      ],
      "metadata": {
        "id": "BPCehPb0V_24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy import optimize"
      ],
      "metadata": {
        "id": "jMGXiGwRV9uE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_movie= 'movie_ids.txt'"
      ],
      "metadata": {
        "id": "oJpx1W2PWTK4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadMovieList():\n",
        "    \"\"\"\n",
        "    Reads the fixed movie list in movie_ids.txt and returns a list of movie names.\n",
        "    Returns\n",
        "    -------\n",
        "    movieNames : list\n",
        "        A list of strings, representing all movie names.\n",
        "    \"\"\"\n",
        "    # Read the fixed movieulary list\n",
        "    with open(path_movie,  encoding='ISO-8859-1') as fid:\n",
        "        movies = fid.readlines()\n",
        "\n",
        "    movieNames = []\n",
        "    for movie in movies:\n",
        "        parts = movie.split()\n",
        "        movieNames.append(' '.join(parts[1:]).strip())\n",
        "    return movieNames"
      ],
      "metadata": {
        "id": "OygRsWRMWVI1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "films_names = loadMovieList()\n",
        "print(f\"Number of movies {len(films_names)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFu1kU2-WW5R",
        "outputId": "80ea49bc-21a1-4ffd-ff4c-692ae24f63b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of movies 1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Рекомендаційні системи\n",
        "\n",
        "In this part of the exercise, you will implement the collaborative filtering learning algorithm and apply it to a dataset of movie ratings ([MovieLens 100k Dataset](https://grouplens.org/datasets/movielens/) from GroupLens Research). This dataset consists of ratings on a scale of 1 to 5. The dataset has $n_u = 943$ users, and $n_m = 1682$ movies.\n",
        "\n",
        "In the next parts of this exercise, you will implement the function `cofiCostFunc` that computes the collaborative filtering objective function and gradient. After implementing the cost function and gradient, you will use `scipy.optimize.minimize` to learn the parameters for collaborative filtering.\n",
        "\n",
        "### 2.1 Movie ratings dataset\n",
        "\n",
        "The next cell will load the dataset `movies.mat`, providing the variables `Y` and `R`.\n",
        "The matrix `Y` (a `num_movies` $\\times$ `num_users` matrix) stores the ratings $y^{(i,j)}$ (from 1 to 5). The matrix `R` is an binary-valued indicator matrix, where $R(i, j) = 1$ if user $j$ gave a rating to movie $i$, and $R(i, j) = 0$ otherwise. The objective of collaborative filtering is to predict movie ratings for the movies that users have not yet rated, that is, the entries with $R(i, j) = 0$. This will allow us to recommend the movies with the highest predicted ratings to the user.\n",
        "\n",
        "To help you understand the matrix `Y`, the following cell will compute the average movie rating for the first movie (Toy Story) and print its average rating."
      ],
      "metadata": {
        "id": "RT9zh_CeXQ8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = loadMovieList()"
      ],
      "metadata": {
        "id": "Ngr1Kd6KWjVe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = loadmat('movies.mat')\n",
        "Y, R = data['Y'], data['R']\n",
        "\n",
        "# Y is a 1682x943 matrix, containing ratings (1-5) of\n",
        "# 1682 movies on 943 users\n",
        "\n",
        "# R is a 1682x943 matrix, where R(i,j) = 1\n",
        "# if and only if user j gave a rating to movie i\n",
        "\n",
        "# From the matrix, we can compute statistics like average rating.\n",
        "print('Average rating for movie 1601 (',names[1601] ,'): %f / 5' %\n",
        "      np.mean(Y[180, R[1601, :]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTkqMC8GWlS4",
        "outputId": "83a73cd3-2092-4d37-fe9b-2c02435e3f6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average rating for movie 1601 ( Price Above Rubies, A (1998) ): 4.984093 / 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Throughout this part of the exercise, you will also be working with the matrices, `X` and `W`:\n",
        "\n",
        "$$ \\text{X} =\n",
        "\\begin{bmatrix}\n",
        "- \\left(x^{(1)}\\right)^T - \\\\\n",
        "- \\left(x^{(2)}\\right)^T - \\\\\n",
        "\\vdots \\\\\n",
        "- \\left(x^{(n_m)}\\right)^T - \\\\\n",
        "\\end{bmatrix}, \\quad\n",
        "\\text{W} =\n",
        "\\begin{bmatrix}\n",
        "- \\left(w^{(1)}\\right)^T - \\\\\n",
        "- \\left(w^{(2)}\\right)^T - \\\\\n",
        "\\vdots \\\\\n",
        "- \\left(w^{(n_u)}\\right)^T - \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "The $i^{th}$ row of `X` corresponds to the feature vector $x^{(i)}$ for the $i^{th}$ movie, and the $j^{th}$ row of `W` corresponds to one parameter vector $w^{(j)}$, for the $j^{th}$ user. Both $x^{(i)}$ and $w^{(j)}$ are n-dimensional vectors. For the purposes of this exercise, you will use $n = 100$, and therefore, $x^{(i)} \\in \\mathbb{R}^{100}$ and $w^{(j)} \\in \\mathbb{R}^{100}$. Correspondingly, `X` is a $n_m \\times 100$ matrix and `W` is a $n_u \\times 100$ matrix.\n",
        "\n",
        "<a id=\"section3\"></a>\n",
        "### 2.2 Collaborative filtering learning algorithm\n",
        "\n",
        "Now, you will start implementing the collaborative filtering learning algorithm. You will start by implementing the cost function (without regularization).\n",
        "\n",
        "The collaborative filtering algorithm in the setting of movie recommendations considers a set of n-dimensional parameter vectors $x^{(1)}, \\dots, x^{(n_m)}$ and $w^{(1)} , \\dots, w^{(n_u)}$, where the model predicts the rating for movie $i$ by user $j$ as $y^{(i,j)} = \\left( w^{(j)} \\right)^T x^{(i)}$. Given a dataset that consists of a set of ratings produced by some users on some movies, you wish to learn the parameter vectors $x^{(1)}, \\dots, x^{(n_m)}, w^{(1)}, \\dots, w^{(n_u)}$ that produce the best fit (minimizes the squared error).\n",
        "\n",
        "You will complete the code in `cofiCostFunc` to compute the cost function and gradient for collaborative filtering. Note that the parameters to the function (i.e., the values that you are trying to learn) are `X` and `W`. In order to use an off-the-shelf minimizer such as `scipy`'s `minimize` function, the cost function has been set up to unroll the parameters into a single vector called `params`. You had previously used the same vector unrolling method in the neural networks programming exercise.\n",
        "\n",
        "#### 2.2.1 Collaborative filtering cost function\n",
        "\n",
        "The collaborative filtering cost function (without regularization) is given by\n",
        "\n",
        "$$\n",
        "J(x^{(1)}, \\dots, x^{(n_m)}, w^{(1)}, \\dots, w^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right)^2\n",
        "$$\n",
        "\n",
        "You should now modify the function `cofiCostFunc` to return this cost in the variable `J`. Note that you should be accumulating the cost for user $j$ and movie $i$ only if `R[i,j] = 1`.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Implementation Note**: We strongly encourage you to use a vectorized implementation to compute $J$, since it will later by called many times by `scipy`'s optimization package. As usual, it might be easiest to first write a non-vectorized implementation (to make sure you have the right answer), and the modify it to become a vectorized implementation (checking that the vectorization steps do not change your algorithm’s output). To come up with a vectorized implementation, the following tip might be helpful: You can use the $R$ matrix to set selected entries to 0. For example, `R * M` will do an element-wise multiplication between `M`\n",
        "and `R`; since `R` only has elements with values either 0 or 1, this has the effect of setting the elements of M to 0 only when the corresponding value in R is 0. Hence, `np.sum( R * M)` is the sum of all the elements of `M` for which the corresponding element in `R` equals 1.\n",
        "</div>\n",
        "\n",
        "<a id=\"cofiCostFunc\"></a>"
      ],
      "metadata": {
        "id": "XEeq5nmLXhm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section4\"></a>\n",
        "#### 2.2.2 Collaborative filtering gradient\n",
        "\n",
        "Now you should implement the gradient (without regularization). Specifically, you should complete the code in `cofiCostFunc` to return the variables `X_grad` and `W_grad`. Note that `X_grad` should be a matrix of the same size as `X` and similarly, `W_grad` is a matrix of the same size as\n",
        "`W`. The gradients of the cost function is given by:\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial x_k^{(i)}} = \\sum_{j:r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right) w_k^{(j)} $$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w_k^{(j)}} = \\sum_{i:r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)}- y^{(i,j)} \\right) x_k^{(j)} $$\n",
        "\n",
        "Note that the function returns the gradient for both sets of variables by unrolling them into a single vector. After you have completed the code to compute the gradients, the next cell run a gradient check\n",
        "(available in `utils.checkCostFunction`) to numerically check the implementation of your gradients (this is similar to the numerical check that you used in the neural networks exercise. If your implementation is correct, you should find that the analytical and numerical gradients match up closely.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Implementation Note:** You can get full credit for this assignment without using a vectorized implementation, but your code will run much more slowly (a small number of hours), and so we recommend that you try to vectorize your implementation. To get started, you can implement the gradient with a for-loop over movies\n",
        "(for computing $\\frac{\\partial J}{\\partial x^{(i)}_k}$) and a for-loop over users (for computing $\\frac{\\partial J}{w_k^{(j)}}$). When you first implement the gradient, you might start with an unvectorized version, by implementing another inner for-loop that computes each element in the summation. After you have completed the gradient computation this way, you should try to vectorize your implementation (vectorize the inner for-loops), so that you are left with only two for-loops (one for looping over movies to compute $\\frac{\\partial J}{\\partial x_k^{(i)}}$ for each movie, and one for looping over users to compute $\\frac{\\partial J}{\\partial w_k^{(j)}}$ for each user).\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Implementation Tip:** To perform the vectorization, you might find this helpful: You should come up with a way to compute all the derivatives associated with $x_1^{(i)} , x_2^{(i)}, \\dots , x_n^{(i)}$ (i.e., the derivative terms associated with the feature vector $x^{(i)}$) at the same time. Let us define the derivatives for the feature vector of the $i^{th}$ movie as:\n",
        "\n",
        "$$ \\left(X_{\\text{grad}} \\left(i, :\\right)\\right)^T =\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial x_1^{(i)}} \\\\\n",
        "\\frac{\\partial J}{\\partial x_2^{(i)}} \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial J}{\\partial x_n^{(i)}}\n",
        "\\end{bmatrix} = \\quad\n",
        "\\sum_{j:r(i,j)=1} \\left( \\left( w^{(j)} \\right)^T x^{(i)} - y^{(i,j)} \\right) w^{(j)}\n",
        "$$\n",
        "\n",
        "To vectorize the above expression, you can start by indexing into `W` and `Y` to select only the elements of interests (that is, those with `r[i, j] = 1`). Intuitively, when you consider the features for the $i^{th}$ movie, you only need to be concerned about the users who had given ratings to the movie, and this allows you to remove all the other users from `W` and `Y`. <br/><br/>\n",
        "\n",
        "\n",
        "Concretely, you can set `idx = np.where(R[i, :] == 1)[0]` to be a list of all the users that have rated movie $i$. This will allow you to create the temporary matrices `W_temp = W[idx, :]` and `Y_temp = Y[i, idx]` that index into `W` and `Y` to give you only the set of users which have rated the $i^{th}$ movie. This will allow you to write the derivatives as: <br>\n",
        "\n",
        "`X_grad[i, :] = np.dot(np.dot(X[i, :], W_temp.T) - Y_temp, W_temp)`\n",
        "\n",
        "<br><br>\n",
        "Note that the vectorized computation above returns a row-vector instead. After you have vectorized the computations of the derivatives with respect to $x^{(i)}$, you should use a similar method to vectorize the derivatives with respect to $w^{(j)}$ as well.\n",
        "</div>"
      ],
      "metadata": {
        "id": "MC5h564fXvNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section5\"></a>\n",
        "#### 2.2.3 Regularized cost function\n",
        "\n",
        "The cost function for collaborative filtering with regularization is given by\n",
        "\n",
        "$$ J(x^{(1)}, \\dots, x^{(n_m)}, w^{(1)}, \\dots, w^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( \\left( w^{(j)} \\right)^T x^{(i)} - y^{(i,j)} \\right)^2 + \\left( \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} \\left( w_k^{(j)} \\right)^2  \\right) + \\left( \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^n \\left(x_k^{(i)} \\right)^2 \\right) $$\n",
        "\n",
        "You should now add regularization to your original computations of the cost function, $J$. After you are done, the next cell will run your regularized cost function, and you should expect to see a cost of about 31.34."
      ],
      "metadata": {
        "id": "b6lJLY18X5rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section6\"></a>\n",
        "#### 2.2.4 Regularized gradient\n",
        "\n",
        "Now that you have implemented the regularized cost function, you should proceed to implement regularization for the gradient. You should add to your implementation in `cofiCostFunc` to return the regularized gradient\n",
        "by adding the contributions from the regularization terms. Note that the gradients for the regularized cost function is given by:\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial x_k^{(i)}} = \\sum_{j:r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right) w_k^{(j)} + \\lambda x_k^{(i)} $$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w_k^{(j)}} = \\sum_{i:r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)}- y^{(i,j)} \\right) x_k^{(j)} + \\lambda w_k^{(j)} $$\n",
        "\n",
        "This means that you just need to add $\\lambda x^{(i)}$ to the `X_grad[i,:]` variable described earlier, and add $\\lambda w^{(j)}$ to the `W_grad[j, :]` variable described earlier."
      ],
      "metadata": {
        "id": "cv1oCt8sX707"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Learning movie recommendations\n",
        "\n",
        "After you have finished implementing the collaborative filtering cost function and gradient, you can now start training your algorithm to make movie recommendations for yourself. In the next cell, you can enter your own movie preferences, so that later when the algorithm runs, you can get your own movie recommendations! We have filled out some values according to our own preferences, but you should change this according to your own tastes. The list of all movies and their number in the dataset can be found listed in the file `Data/movie_idx.txt`."
      ],
      "metadata": {
        "id": "oE3IGK-AX_xT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movieList = loadMovieList()"
      ],
      "metadata": {
        "id": "LB4QczpRYBfb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_id_list = [0, 97, 6, 11, 53, 63, 65, 68, 182, 225, 354]\n",
        "\n",
        "for movie in movies_id_list:\n",
        "  print(movieList[movie])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yCyQgEoYF1-",
        "outputId": "31e652b4-74db-4b63-aa78-5c520885195e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toy Story (1995)\n",
            "Silence of the Lambs, The (1991)\n",
            "Twelve Monkeys (1995)\n",
            "Usual Suspects, The (1995)\n",
            "Outbreak (1995)\n",
            "Shawshank Redemption, The (1994)\n",
            "While You Were Sleeping (1995)\n",
            "Forrest Gump (1994)\n",
            "Alien (1979)\n",
            "Die Hard 2 (1990)\n",
            "Sphere (1998)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.1 Recommendations\n",
        "\n",
        "After the additional ratings have been added to the dataset, the script\n",
        "will proceed to train the collaborative filtering model. This will learn the\n",
        "parameters `X` and `W`. To predict the rating of movie $i$ for user $j$, you need to compute $(w^{(j)})^T x^{(i)}$ . The next part of the script computes the ratings for\n",
        "all the movies and users and displays the movies that it recommends (Figure\n",
        "4), according to ratings that were entered earlier in the script. Note that\n",
        "you might obtain a different set of the predictions due to different random\n",
        "initializations."
      ],
      "metadata": {
        "id": "6ge9eZgRYI-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeRatings(Y, R):\n",
        "    count_movies, count_users = Y.shape\n",
        "    Y_mean_rating = np.zeros(count_movies)\n",
        "    Y_norm_rating= np.zeros(Y.shape)\n",
        "\n",
        "    for i in range(count_movies):\n",
        "        idx = R[i, :] == 1\n",
        "        Y_mean_rating[i] = np.mean(Y[i, idx])\n",
        "        Y_norm_rating[i, idx] = Y[i, idx] - Y_mean_rating[i]\n",
        "\n",
        "    return Y_norm_rating, Y_mean_rating"
      ],
      "metadata": {
        "id": "xrRXkSprYLEK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вирахуємо чисельний градіент функції J за параметром theta"
      ],
      "metadata": {
        "id": "-L4_nstdYPV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeNumericalGradient(J, theta, e=1e-4):\n",
        "    array_for_numeric_gradient = np.zeros(theta.shape)\n",
        "    diagonal_matrix_e = np.diag(e * np.ones(theta.shape))  #\n",
        "\n",
        "    for i in range(theta.size):\n",
        "        first_loss, _ = J(theta - diagonal_matrix_e[:, i])\n",
        "        second_loss, _ = J(theta + diagonal_matrix_e[:, i])\n",
        "\n",
        "        array_for_numeric_gradient[i] = (second_loss - first_loss) / (2 * e)\n",
        "\n",
        "    return array_for_numeric_gradient"
      ],
      "metadata": {
        "id": "vlcZRMUMYQ95"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перевіряємо коректність реалізації функції вартості за допомогою числового градієнта"
      ],
      "metadata": {
        "id": "1sX4JEipYaJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkCostFunction(cofiCostFunc, lambda_=0.):\n",
        "\n",
        "    #Створимо контрольну точку для перевірки реалізації функції вартості\n",
        "    random_users = 5\n",
        "    random_movies = 4\n",
        "    random_features = 3\n",
        "\n",
        "    X_t = np.random.rand(random_movies, random_features)\n",
        "    Theta_t = np.random.rand(random_users, random_features)\n",
        "\n",
        "    #Замінюємо більшість записів на 0\n",
        "    Y = np.dot(X_t, Theta_t.T)\n",
        "    Y[np.random.rand(*Y.shape) > 0.5] = 0\n",
        "    R = np.zeros(Y.shape)\n",
        "    R[Y != 0] = 1\n",
        "\n",
        "    #Запускаємо перевірку градієнта\n",
        "    X = np.random.randn(*X_t.shape)\n",
        "    Theta = np.random.randn(*Theta_t.shape)\n",
        "\n",
        "    #Об'єднуємо параметри в один вектор\n",
        "    params = np.concatenate([X.ravel(), Theta.ravel()])\n",
        "\n",
        "    #Обчислюємо чисельний градієнт\n",
        "    numerical_gradient = computeNumericalGradient(\n",
        "        lambda x: cofiCostFunc(x,\n",
        "                               Y,\n",
        "                               R,\n",
        "                               random_users,\n",
        "                               random_movies,\n",
        "                               random_features,\n",
        "                               lambda_), params)\n",
        "\n",
        "    #Обчислюємо аналітичний градієнт\n",
        "    cost, analytical_gradient = cofiCostFunc(params,\n",
        "                              Y,\n",
        "                              R,\n",
        "                              random_users,\n",
        "                              random_movies,\n",
        "                              random_features,\n",
        "                              lambda_)\n",
        "\n",
        "\n",
        "    print(\"чисельний градієнт:\", numerical_gradient)\n",
        "    print(\"аналітичний градієнт:\", analytical_gradient)\n",
        "\n",
        "    #Обчислюємо відносну різницю між чисельним та аналітичним градієнтами\n",
        "    diff = np.linalg.norm(numerical_gradient - analytical_gradient) / np.linalg.norm(numerical_gradient + analytical_gradient)\n",
        "\n",
        "    print('відносна різниця між чисельним та аналітичнм градієнтом', diff)\n"
      ],
      "metadata": {
        "id": "zNfU2c-pYa0z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обчислюємо функцію вартості та її градієнт для алгоритму колаборативної фільтрації\n",
        "\n"
      ],
      "metadata": {
        "id": "OtYcpiIQYeVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cofiCostFunc(params, Y, R, num_users, num_movies, num_features, lambda_=0.0):\n",
        "\n",
        "    #Розпаковуємо матриці X і Theta з параметрів\n",
        "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
        "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
        "\n",
        "    #ініціалізуємо змінні для функції вартості та градієнта\n",
        "    J = 0\n",
        "    X_grad = np.zeros(X.shape)\n",
        "    Theta_grad = np.zeros(Theta.shape)\n",
        "\n",
        "    #Обчислюємо функцію вартості\n",
        "    J = (1 / 2) * np.sum(np.square((X.dot(Theta.T) - Y) * R)) + \\\n",
        "        (lambda_ / 2) * np.sum(np.square(X)) + \\\n",
        "        (lambda_ / 2) * np.sum(np.square(Theta))\n",
        "\n",
        "    #обчислюємо градієнт за факторами фільмів (X) і користувачами (Theta)\n",
        "    for i in range(R.shape[0]):\n",
        "        idx = np.where(R[i, :] == 1)[0]\n",
        "        Theta_temp = Theta[idx, :]\n",
        "        Y_temp = Y[i, idx]\n",
        "        X_grad[i, :] = np.dot(np.dot(X[i, :], Theta_temp.T) - Y_temp, Theta_temp) + lambda_ * X[i, :]\n",
        "\n",
        "    for j in range(R.shape[1]):\n",
        "        idx = np.where(R[:, j] == 1)[0]\n",
        "        X_temp = X[idx, :]\n",
        "        Y_temp = Y[idx, j]\n",
        "        Theta_grad[j, :] = np.dot(np.dot(X_temp, Theta[j, :]) - Y_temp, X_temp) + lambda_ * Theta[j, :]\n",
        "\n",
        "    #об'єднуємо градієнти в один вектор і повертаємо результати\n",
        "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
        "    return J, grad"
      ],
      "metadata": {
        "id": "PetJfr76YgkM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkCostFunction(cofiCostFunc, 1.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwPrO-WSY02D",
        "outputId": "c1a16a16-5033-41d5-f077-4c0a3a40253a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "чисельний градієнт: [-10.00115294  -3.53379813  -0.22180219  -3.95820597   2.06363805\n",
            "  -2.97308069   2.68716914   0.99338144  -1.75085919  -0.15538193\n",
            "   1.54904569   2.79821903 -10.85787652  -2.55899697   1.32418213\n",
            "   0.83943335  -2.78229378  -1.85312749   6.37082529   3.41013921\n",
            "  -2.96213996   4.40355522  -1.71695223   2.56476077   0.01412526\n",
            "  -0.42732825   0.03361654]\n",
            "аналітичний градієнт: [-10.00115294  -3.53379813  -0.22180219  -3.95820597   2.06363805\n",
            "  -2.97308069   2.68716914   0.99338144  -1.75085919  -0.15538193\n",
            "   1.54904569   2.79821903 -10.85787652  -2.55899697   1.32418213\n",
            "   0.83943335  -2.78229378  -1.85312749   6.37082529   3.41013921\n",
            "  -2.96213996   4.40355522  -1.71695223   2.56476077   0.01412526\n",
            "  -0.42732825   0.03361654]\n",
            "відносна різниця між чисельним та аналітичнм градієнтом 2.756332269034923e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movieList = loadMovieList()\n",
        "n_movies = len(movieList)\n",
        "my_ratings = np.zeros(n_movies)\n",
        "\n",
        "movies_to_rate = np.random.choice(n_movies, size=10, replace=False)\n",
        "\n",
        "for movie_idx in movies_to_rate:\n",
        "    rating = np.random.randint(2, 6)\n",
        "    my_ratings[movie_idx] = rating\n",
        "\n",
        "\n",
        "print(\"Підсумкові оцінки для випадково обраних фільмів:\")\n",
        "for idx, rating in enumerate(my_ratings):\n",
        "    if idx in movies_to_rate:\n",
        "        movie_title = movieList[idx]\n",
        "        print(f\"Фільм: {movie_title}, Оцінка: {rating}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoMFevcSZwTe",
        "outputId": "3590ab03-746d-4113-8f69-1dc37bac72a9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Підсумкові оцінки для випадково обраних фільмів:\n",
            "Фільм: As Good As It Gets (1997), Оцінка: 5.0\n",
            "Фільм: Children of the Corn: The Gathering (1996), Оцінка: 4.0\n",
            "Фільм: Bringing Up Baby (1938), Оцінка: 3.0\n",
            "Фільм: Whole Wide World, The (1996), Оцінка: 4.0\n",
            "Фільм: Charade (1963), Оцінка: 4.0\n",
            "Фільм: Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991), Оцінка: 5.0\n",
            "Фільм: Getaway, The (1994), Оцінка: 4.0\n",
            "Фільм: Street Fighter (1994), Оцінка: 2.0\n",
            "Фільм: Show, The (1995), Оцінка: 4.0\n",
            "Фільм: Tainted (1998), Оцінка: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Додамо власні оцінки до матриці даних\n",
        "Y = np.hstack([my_ratings[:, None], Y])\n",
        "R = np.hstack([(my_ratings > 0)[:, None], R])\n",
        "\n",
        "# Нормалізуємо оцінки\n",
        "Ynorm, Ymean = normalizeRatings(Y, R)\n",
        "\n",
        "# Визначаємо кількості фільмів і користувачів\n",
        "random_movies, random_users = Y.shape\n",
        "\n",
        "# Встановлюэмо кількості ознак\n",
        "random_features = 7\n",
        "\n",
        "# Ініціалізація параметрів (Theta, X)\n",
        "X = np.random.randn(random_movies, random_features)\n",
        "Theta = np.random.randn(random_users, random_features)\n",
        "\n",
        "# Об'єднання параметрів в один вектор\n",
        "initial_parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
        "\n",
        "# Встановлення параметрів для алгоритму оптимізації\n",
        "options = {'maxfun': 100}\n",
        "\n",
        "# Встановлення параметра регуляризації\n",
        "lambda_ = 10\n",
        "\n",
        "# Оптимізація параметрів за допомогою алгоритму TNC\n",
        "res = optimize.minimize(lambda x: cofiCostFunc(x, Ynorm, R, random_users,\n",
        "                                               random_movies, random_features, lambda_),\n",
        "                        initial_parameters,\n",
        "                        method='TNC',\n",
        "                        jac=True,\n",
        "                        options=options)\n",
        "theta = res.x\n",
        "\n",
        "# Розгортання повернутої theta назад у матриці X і Theta\n",
        "X = theta[:random_movies*random_features].reshape(random_movies, random_features)\n",
        "Theta = theta[random_movies*random_features:].reshape(random_users, random_features)"
      ],
      "metadata": {
        "id": "p7YdOWTPZ0Y6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ratings = np.dot(X, Theta.T)\n",
        "# Додавання середньої оцінки для кожного фільму\n",
        "my_predictions = predicted_ratings[:, 0] + Ymean\n",
        "\n",
        "# Завантаження списку фільмів\n",
        "movieList = loadMovieList()\n",
        "\n",
        "# Отримання індексів фільмів у порядку убування передбачених рейтингів\n",
        "sorted_indices = np.argsort(my_predictions)[::-1]\n",
        "\n",
        "# Виведення топ-20 рекомендацій для користувача\n",
        "print('Топ рекомендацій для вас:')\n",
        "\n",
        "for i in range(20):\n",
        "    index = sorted_indices[i]\n",
        "    print('Передбачуваний рейтинг %.1f для фільму %s' % (my_predictions[index], movieList[index]))\n",
        "\n",
        "# Виведення вихідних оцінок, наданих користувачем\n",
        "print('\\nПочаткові оцінки:')\n",
        "for i in range(len(my_ratings)):\n",
        "    if my_ratings[i] > 0:\n",
        "        print('Оцінка %d для фільму %s' % (my_ratings[i], movieList[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFjZWrBWaIIn",
        "outputId": "2401224b-bab1-43bd-8508-a67e6218b272"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ рекомендацій для вас:\n",
            "Передбачуваний рейтинг 5.0 для фільму They Made Me a Criminal (1939)\n",
            "Передбачуваний рейтинг 5.0 для фільму Prefontaine (1997)\n",
            "Передбачуваний рейтинг 5.0 для фільму Saint of Fort Washington, The (1993)\n",
            "Передбачуваний рейтинг 5.0 для фільму Marlene Dietrich: Shadow and Light (1996)\n",
            "Передбачуваний рейтинг 5.0 для фільму Entertaining Angels: The Dorothy Day Story (1996)\n",
            "Передбачуваний рейтинг 5.0 для фільму Santa with Muscles (1996)\n",
            "Передбачуваний рейтинг 5.0 для фільму Aiqing wansui (1994)\n",
            "Передбачуваний рейтинг 5.0 для фільму Someone Else's America (1995)\n",
            "Передбачуваний рейтинг 5.0 для фільму Great Day in Harlem, A (1994)\n",
            "Передбачуваний рейтинг 5.0 для фільму Star Kid (1997)\n",
            "Передбачуваний рейтинг 4.6 для фільму Schindler's List (1993)\n",
            "Передбачуваний рейтинг 4.6 для фільму Pather Panchali (1955)\n",
            "Передбачуваний рейтинг 4.6 для фільму Shawshank Redemption, The (1994)\n",
            "Передбачуваний рейтинг 4.5 для фільму Casablanca (1942)\n",
            "Передбачуваний рейтинг 4.5 для фільму Maya Lin: A Strong Clear Vision (1994)\n",
            "Передбачуваний рейтинг 4.5 для фільму Some Mother's Son (1996)\n",
            "Передбачуваний рейтинг 4.5 для фільму Anna (1996)\n",
            "Передбачуваний рейтинг 4.5 для фільму Everest (1998)\n",
            "Передбачуваний рейтинг 4.5 для фільму Close Shave, A (1995)\n",
            "Передбачуваний рейтинг 4.5 для фільму Rear Window (1954)\n",
            "\n",
            "Початкові оцінки:\n",
            "Оцінка 5 для фільму As Good As It Gets (1997)\n",
            "Оцінка 4 для фільму Children of the Corn: The Gathering (1996)\n",
            "Оцінка 3 для фільму Bringing Up Baby (1938)\n",
            "Оцінка 4 для фільму Whole Wide World, The (1996)\n",
            "Оцінка 4 для фільму Charade (1963)\n",
            "Оцінка 5 для фільму Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)\n",
            "Оцінка 4 для фільму Getaway, The (1994)\n",
            "Оцінка 2 для фільму Street Fighter (1994)\n",
            "Оцінка 4 для фільму Show, The (1995)\n",
            "Оцінка 5 для фільму Tainted (1998)\n"
          ]
        }
      ]
    }
  ]
}